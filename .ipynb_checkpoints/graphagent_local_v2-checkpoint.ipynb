{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "We are to say exactly: \"setup successful.\"\n",
      " The instruction says: \"Say exactly: setup successful.\"\n",
      " So we output the string \"setup successful.\" (note: the example has a period at the end)\n",
      "\n",
      " However, note: the example in the instruction says: \"setup successful.\" (with a period) but the user wrote without a period in the instruction? \n",
      " Let me re-read: the user says: \"Say exactly: setup successful.\"\n",
      "\n",
      " But in the user's message, it's written as: \"setup successful.\" (with a period) in the example? Actually, the user wrote: \"setup successful.\" (with a period) in the instruction.\n",
      "\n",
      " But wait, the user's message: \"Say exactly: setup successful.\" -> the colon and then the string \"setup successful.\" (with a period at the end).\n",
      "\n",
      " However, the problem says: \"Say exactly: setup successful.\" meaning we have to output the string exactly as: \"setup successful.\" (with a period).\n",
      "\n",
      " But note: the user wrote \"setup successful.\" (with a period) in the instruction? Actually, in the user's message, it's written without a period? \n",
      "\n",
      " Let me look: the user says: \"Say exactly: setup successful.\"\n",
      "\n",
      " In the user's message, the string they want is: \"setup successful.\" (with a as the first letter? and the period at the end?).\n",
      "\n",
      " Actually, the problem says: \"setup successful.\" -> so we output that string.\n",
      "\n",
      " However, the problem says: \"Say exactly: setup successful.\" meaning the string we output should be: \"setup successful.\" (with a period at the end).\n",
      "\n",
      " But note: the user wrote the string without a period? Wait, in the user's message it's written as: \"setup successful.\" (with a period) because the user used a period at the end of the sentence.\n",
      "\n",
      " However, the problem says: \"setup successful.\" (with a period) because the user wrote it with a period.\n",
      "\n",
      " But the instruction says: \"Say exactly: setup successful.\" -> so we output the string: \"setup successful.\" (with a period).\n",
      "\n",
      " However, the problem says: \"setup successful.\" (with a period) but in the context of the problem, we are to output that string.\n",
      "\n",
      " Let me write it: the string is \"setup successful.\" (with a period at the end).\n",
      "\n",
      " But note: the problem says \"setup successful\" (without a period) in the instruction? Actually, the user wrote: \"setup successful.\"\n"
     ]
    }
   ],
   "source": [
    "# --- Local OpenAI-compatible client (LM Studio / Ollama) ---\n",
    "# Endpoint: http://127.0.0.1:1234  (your server)\n",
    "# Model:    qwen/qwen3-4b-thinking-2507\n",
    "\n",
    "%pip install -q openai\n",
    "\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "BASE_URL = \"http://127.0.0.1:1234/v1\"      # <‚Äî your server\n",
    "API_KEY  = \"sk-local\"                      # <‚Äî dummy key, any string works\n",
    "MODEL = \"qwen/qwen2.5-vl-7b\"               # <‚Äî from your models list\n",
    "\n",
    "client = OpenAI(base_url=BASE_URL, api_key=API_KEY)\n",
    "\n",
    "def local_chat(prompt: str, *, system: str | None = None,\n",
    "               temperature: float = 0.2, max_tokens: int = 512,\n",
    "               model: str = \"qwen/qwen2.5-vl-7b\") -> str:\n",
    "    msgs = []\n",
    "    if system:\n",
    "        msgs.append({\"role\": \"system\", \"content\": system})\n",
    "    msgs.append({\"role\": \"user\", \"content\": prompt})\n",
    "    resp = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=msgs,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    raw = resp.choices[0].message.content.strip()\n",
    "    return clean_thinking_output(raw)\n",
    "\n",
    "\n",
    "def clean_thinking_output(text: str) -> str:\n",
    "    # If the model outputs <think>‚Ä¶</think>, strip that part\n",
    "    if \"</think>\" in text:\n",
    "        return text.split(\"</think>\")[-1].strip()\n",
    "    if \"<think>\" in text:\n",
    "        return text.split(\"<think>\")[-1].strip()\n",
    "    return text.strip()    \n",
    "    \n",
    "\n",
    "# quick smoketest:\n",
    "print(local_chat(\"Say exactly: setup successful.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "-X3WmICe5myt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gmoores\\AI-Tutorial-Codes-Included\\venv\\Scripts\\python.exe\n",
      "C:\\Users\\gmoores\\AI-Tutorial-Codes-Included\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "print(sys.executable)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-X3WmICe5myt"
   },
   "outputs": [],
   "source": [
    "import os, json, time, ast, math, getpass\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Dict, List, Callable, Any\n",
    "import google.generativeai as genai\n",
    "\n",
    "try:\n",
    "    import networkx as nx\n",
    "except ImportError:\n",
    "    nx = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4PgAdOT05q13"
   },
   "outputs": [],
   "source": [
    "def make_model(api_key: str, model_name: str = \"gemini-1.5-flash\"):\n",
    "    genai.configure(api_key=api_key)\n",
    "    return genai.GenerativeModel(model_name, system_instruction=(\n",
    "        \"You are GraphAgent, a principled planner-executor. \"\n",
    "        \"Prefer structured, concise outputs; use provided tools when asked.\"\n",
    "    ))\n",
    "\n",
    "def call_llm(model, prompt: str, temperature=0.2) -> str:\n",
    "    r = model.generate_content(prompt, generation_config={\"temperature\": temperature})\n",
    "    return (r.text or \"\").strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0jrDj0nz5tDO"
   },
   "outputs": [],
   "source": [
    "def safe_eval_math(expr: str) -> str:\n",
    "    node = ast.parse(expr, mode=\"eval\")\n",
    "    allowed = (ast.Expression, ast.BinOp, ast.UnaryOp, ast.Num, ast.Constant,\n",
    "               ast.Add, ast.Sub, ast.Mult, ast.Div, ast.Pow, ast.Mod,\n",
    "               ast.USub, ast.UAdd, ast.FloorDiv, ast.AST)\n",
    "    def check(n):\n",
    "        if not isinstance(n, allowed): raise ValueError(\"Unsafe expression\")\n",
    "        for c in ast.iter_child_nodes(n): check(c)\n",
    "    check(node)\n",
    "    return str(eval(compile(node, \"<math>\", \"eval\"), {\"__builtins__\": {}}, {}))\n",
    "\n",
    "DOCS = [\n",
    "    \"Solar panels convert sunlight to electricity; capacity factor ~20%.\",\n",
    "    \"Wind turbines harvest kinetic energy; onshore capacity factor ~35%.\",\n",
    "    \"RAG = retrieval-augmented generation joins search with prompting.\",\n",
    "    \"LangGraph enables cyclic graphs of agents; good for tool orchestration.\",\n",
    "]\n",
    "def search_docs(q: str, k: int = 3) -> List[str]:\n",
    "    ql = q.lower()\n",
    "    scored = sorted(DOCS, key=lambda d: -sum(w in d.lower() for w in ql.split()))\n",
    "    return scored[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eBYrj_Eb5uI_"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class State:\n",
    "    task: str\n",
    "    plan: str = \"\"\n",
    "    scratch: List[str] = field(default_factory=list)\n",
    "    evidence: List[str] = field(default_factory=list)\n",
    "    result: str = \"\"\n",
    "    step: int = 0\n",
    "    done: bool = False\n",
    "\n",
    "def node_plan(state: State, model) -> str:\n",
    "    prompt = f\"\"\"Plan step-by-step to solve the user task.\n",
    "Task: {state.task}\n",
    "Return JSON: {{\"subtasks\": [\"...\"], \"tools\": {{\"search\": true/false, \"math\": true/false}}, \"success_criteria\": [\"...\"]}}\"\"\"\n",
    "    js = call_llm(model, prompt)\n",
    "    try:\n",
    "        plan = json.loads(js[js.find(\"{\"): js.rfind(\"}\")+1])\n",
    "    except Exception:\n",
    "        plan = {\"subtasks\": [\"Research\", \"Synthesize\"], \"tools\": {\"search\": True, \"math\": False}, \"success_criteria\": [\"clear answer\"]}\n",
    "    state.plan = json.dumps(plan, indent=2)\n",
    "    state.scratch.append(\"PLAN:\\n\"+state.plan)\n",
    "    return \"route\"\n",
    "\n",
    "def node_route(state: State, model) -> str:\n",
    "    prompt = f\"\"\"You are a router. Decide next node.\n",
    "Context scratch:\\n{chr(10).join(state.scratch[-5:])}\n",
    "If math needed -> 'math', if research needed -> 'research', if ready -> 'write'.\n",
    "Return one token from [research, math, write]. Task: {state.task}\"\"\"\n",
    "    choice = call_llm(model, prompt).lower()\n",
    "    if \"math\" in choice and any(ch.isdigit() for ch in state.task):\n",
    "        return \"math\"\n",
    "    if \"research\" in choice or not state.evidence:\n",
    "        return \"research\"\n",
    "    return \"write\"\n",
    "\n",
    "def node_research(state: State, model) -> str:\n",
    "    prompt = f\"\"\"Generate 3 focused search queries for:\n",
    "Task: {state.task}\n",
    "Return as JSON list of strings.\"\"\"\n",
    "    qjson = call_llm(model, prompt)\n",
    "    try:\n",
    "        queries = json.loads(qjson[qjson.find(\"[\"): qjson.rfind(\"]\")+1])[:3]\n",
    "    except Exception:\n",
    "        queries = [state.task, \"background \"+state.task, \"pros cons \"+state.task]\n",
    "    hits = []\n",
    "    for q in queries:\n",
    "        hits.extend(search_docs(q, k=2))\n",
    "    state.evidence.extend(list(dict.fromkeys(hits)))\n",
    "    state.scratch.append(\"EVIDENCE:\\n- \" + \"\\n- \".join(hits))\n",
    "    return \"route\"\n",
    "\n",
    "def node_math(state: State, model) -> str:\n",
    "    prompt = \"Extract a single arithmetic expression from this task:\\n\"+state.task\n",
    "    expr = call_llm(model, prompt)\n",
    "    expr = \"\".join(ch for ch in expr if ch in \"0123456789+-*/().%^ \")\n",
    "    try:\n",
    "        val = safe_eval_math(expr)\n",
    "        state.scratch.append(f\"MATH: {expr} = {val}\")\n",
    "    except Exception as e:\n",
    "        state.scratch.append(f\"MATH-ERROR: {expr} ({e})\")\n",
    "    return \"route\"\n",
    "\n",
    "def node_write(state: State, model) -> str:\n",
    "    prompt = f\"\"\"Write the final answer.\n",
    "Task: {state.task}\n",
    "Use the evidence and any math results below, cite inline like [1],[2].\n",
    "Evidence:\\n{chr(10).join(f'[{i+1}] '+e for i,e in enumerate(state.evidence))}\n",
    "Notes:\\n{chr(10).join(state.scratch[-5:])}\n",
    "Return a concise, structured answer.\"\"\"\n",
    "    draft = call_llm(model, prompt, temperature=0.3)\n",
    "    state.result = draft\n",
    "    state.scratch.append(\"DRAFT:\\n\"+draft)\n",
    "    return \"critic\"\n",
    "\n",
    "def node_critic(state: State, model) -> str:\n",
    "    prompt = f\"\"\"Critique and improve the answer for factuality, missing steps, and clarity.\n",
    "If fix needed, return improved answer. Else return 'OK'.\n",
    "Answer:\\n{state.result}\\nCriteria:\\n{state.plan}\"\"\"\n",
    "    crit = call_llm(model, prompt)\n",
    "    if crit.strip().upper() != \"OK\" and len(crit) > 30:\n",
    "        state.result = crit.strip()\n",
    "        state.scratch.append(\"REVISED\")\n",
    "    state.done = True\n",
    "    return \"end\"\n",
    "\n",
    "NODES: Dict[str, Callable[[State, Any], str]] = {\n",
    "    \"plan\": node_plan, \"route\": node_route, \"research\": node_research,\n",
    "    \"math\": node_math, \"write\": node_write, \"critic\": node_critic\n",
    "}\n",
    "\n",
    "def run_graph(task: str, api_key: str) -> State:\n",
    "    model = make_model(api_key)\n",
    "    state = State(task=task)\n",
    "    cur = \"plan\"\n",
    "    max_steps = 12\n",
    "    while not state.done and state.step < max_steps:\n",
    "        state.step += 1\n",
    "        nxt = NODES[cur](state, model)\n",
    "        if nxt == \"end\": break\n",
    "        cur = nxt\n",
    "    return state\n",
    "\n",
    "def ascii_graph():\n",
    "    return \"\"\"\n",
    "START -> plan -> route -> (research <-> route) & (math <-> route) -> write -> critic -> END\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 882
    },
    "id": "_ID2dD6Q5HHn",
    "outputId": "51ea467e-b8c5-4aa7-8eef-ba9373a8c2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîê Enter GEMINI_API_KEY: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
      "üìù Enter your task: \n",
      "\n",
      "=== GRAPH === \n",
      "START -> plan -> route -> (research <-> route) & (math <-> route) -> write -> critic -> END\n",
      "\n",
      "\n",
      "‚úÖ Result in 11.45s:\n",
      "The answer is factually incorrect in its claim of wind power being *more* reliable than solar power based solely on capacity factors. While it correctly states the approximate capacity factors, it omits crucial context.  Capacity factor is only one aspect of reliability;  intermittency and predictability are also vital. Solar power's output is more predictable during daylight hours, while wind power's output is more variable due to fluctuating wind speeds.  The inclusion of \"5 * 7 = 35\" is irrelevant and detracts from the answer.\n",
      "\n",
      "\n",
      "Improved Answer:\n",
      "\n",
      "Wind and solar power are both intermittent renewable energy sources, but differ in their reliability profiles.  While onshore wind power generally exhibits a higher capacity factor (around 35%) than solar photovoltaic (around 20%), this alone doesn't fully capture reliability.  Solar power's output is more predictable during daylight hours, making it easier to forecast and integrate into the grid. Wind power's output is more variable due to unpredictable wind speeds.  A comprehensive assessment of reliability requires considering factors beyond capacity factor, including geographic location, technological advancements (e.g., improved forecasting models), and grid integration strategies.  Therefore, a simple comparison based solely on capacity factor is insufficient to definitively declare one technology more reliable than the other.\n",
      "\n",
      "---- Evidence ----\n",
      "Solar panels convert sunlight to electricity; capacity factor ~20%.\n",
      "Wind turbines harvest kinetic energy; onshore capacity factor ~35%.\n",
      "\n",
      "---- Scratch (last 5) ----\n",
      "PLAN:\n",
      "{\n",
      "  \"subtasks\": [\n",
      "    \"Search for information comparing the reliability of solar and wind power generation.\",\n",
      "    \"Summarize the findings regarding reliability, considering factors like intermittency, predictability, and capacity factors.\",\n",
      "    \"Compute 5 * 7\"\n",
      "  ],\n",
      "  \"tools\": {\n",
      "    \"search\": true,\n",
      "    \"math\": true\n",
      "  },\n",
      "  \"success_criteria\": [\n",
      "    \"A summary comparing the reliability of solar and wind power is produced.\",\n",
      "    \"The calculation 5 * 7 is correctly performed and the result is reported.\"\n",
      "  ]\n",
      "}\n",
      "EVIDENCE:\n",
      "- Solar panels convert sunlight to electricity; capacity factor ~20%.\n",
      "- Wind turbines harvest kinetic energy; onshore capacity factor ~35%.\n",
      "- Wind turbines harvest kinetic energy; onshore capacity factor ~35%.\n",
      "- Solar panels convert sunlight to electricity; capacity factor ~20%.\n",
      "- Solar panels convert sunlight to electricity; capacity factor ~20%.\n",
      "- Wind turbines harvest kinetic energy; onshore capacity factor ~35%.\n",
      "DRAFT:\n",
      "Wind power is more reliable than solar power based on capacity factors [1, 2].  Onshore wind has a capacity factor of ~35%, while solar has a capacity factor of ~20% [1, 2].  5 * 7 = 35.\n",
      "REVISED\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    key = os.getenv(\"GEMINI_API_KEY\") or getpass.getpass(\"üîê Enter GEMINI_API_KEY: \")\n",
    "    task = input(\"üìù Enter your task: \").strip() or \"Compare solar vs wind for reliability; compute 5*7.\"\n",
    "    t0 = time.time()\n",
    "    state = run_graph(task, key)\n",
    "    dt = time.time() - t0\n",
    "    print(\"\\n=== GRAPH ===\", ascii_graph())\n",
    "    print(f\"\\n‚úÖ Result in {dt:.2f}s:\\n{state.result}\\n\")\n",
    "    print(\"---- Evidence ----\")\n",
    "    print(\"\\n\".join(state.evidence))\n",
    "    print(\"\\n---- Scratch (last 5) ----\")\n",
    "    print(\"\\n\".join(state.scratch[-5:]))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
